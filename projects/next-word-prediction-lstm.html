<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="Next-Word Prediction using LSTM - Deep learning model for sequence prediction and spam detection.">
  <meta name="theme-color" content="#0066cc">

  <!-- Open Graph -->
  <meta property="og:title" content="Next-Word Prediction Model Using LSTM">
  <meta property="og:description" content="Deep learning NLP project using TensorFlow and LSTM for sequence prediction">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://arjun-malgwa.github.io/projects/next-word-prediction-lstm.html">

  <!-- JSON-LD Schema -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org/",
    "@type": "BreadcrumbList",
    "itemListElement": [
      {
        "@type": "ListItem",
        "position": 1,
        "name": "Home",
        "item": "https://arjun-malgwa.github.io"
      },
      {
        "@type": "ListItem",
        "position": 2,
        "name": "Projects",
        "item": "https://arjun-malgwa.github.io/projects/"
      },
      {
        "@type": "ListItem",
        "position": 3,
        "name": "LSTM Next-Word Prediction",
        "item": "https://arjun-malgwa.github.io/projects/next-word-prediction-lstm.html"
      }
    ]
  }
  </script>

  <title>LSTM Next-Word Prediction - Arjun Malgwa</title>
  <link rel="canonical" href="https://arjun-malgwa.github.io/projects/next-word-prediction-lstm.html">
  <link rel="preload" href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" as="style">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap">
  <link rel="stylesheet" href="/assets/css/styles.css">
  <link rel="stylesheet" href="/assets/css/motion.css">
</head>
<body>
  <a href="#main" class="skip-link">Skip to main content</a>

  <header>
    <div class="header-content">
      <a href="/" class="logo">Arjun</a>
      <button class="menu-toggle" aria-label="Toggle menu" aria-expanded="false">‚ò∞</button>
      <nav>
        <a href="/">Home</a>
        <a href="/about.html">About</a>
        <a href="/projects/">Projects</a>
        <a href="/experience.html">Experience</a>
        <a href="/dashboards.html">Dashboards</a>
        <a href="/resume.html">Resume</a>
        <a href="/contact.html">Contact</a>
      </nav>
      <button class="theme-toggle" aria-label="Toggle theme">üåô</button>
    </div>
  </header>

  <div class="breadcrumb">
    <a href="/">Home</a>
    <span>/</span>
    <a href="/projects/">Projects</a>
    <span>/</span>
    <span aria-current="page">LSTM Next-Word Prediction</span>
  </div>

  <main id="main" class="container-narrow">
    <article>
      <h1>Next-Word Prediction Model Using LSTM</h1>
      <p style="font-size: 1.1rem; color: rgba(0, 0, 0, 0.7); margin-bottom: 2rem;">Apr 2024 - Jun 2024 | Deep Learning Project</p>

      <section>
        <h2>Challenge & Objective</h2>
        <p>Building an intelligent text prediction system requires understanding sequential patterns in language. This project explored LSTM (Long Short-Term Memory) networks for next-word prediction, comparing their performance against CNN and RNN alternatives for applications in predictive text and spam detection.</p>
      </section>

      <section>
        <h2>Approach & Methodology</h2>

        <h3 style="margin-top: 1.5rem;">1. Dataset & Preprocessing</h3>
        <p>Built an LSTM model using the SMS Spam Collection Dataset (UCI) to predict next-word sequences. Applied comprehensive text preprocessing including stopword removal, tokenization, and padding to prepare data for neural network training.</p>

        <h3 style="margin-top: 1.5rem;">2. Architecture Comparison</h3>
        <p>Compared CNN, RNN, and LSTM architectures on the same dataset to identify the optimal approach. Tested multiple configurations to evaluate effectiveness across different deep learning architectures for sequence prediction tasks.</p>

        <h3 style="margin-top: 1.5rem;">3. Business Applications</h3>
        <p>Demonstrated the business potential of the model to improve user engagement and reduce misclassification in automated text systems such as predictive text input and spam detection mechanisms.</p>
      </section>

      <section>
        <h2>Results & Impact</h2>
        <ul style="list-style: disc; padding-left: 2rem;">
          <li><strong>LSTM Optimization:</strong> Achieved optimal performance with LSTM for long-term sequence dependencies</li>
          <li><strong>Accuracy Metrics:</strong> Strong performance on next-word prediction with effective text preprocessing</li>
          <li><strong>Business Potential:</strong> Demonstrated improved user engagement and reduced misclassification in automated text systems</li>
          <li><strong>Architecture Insights:</strong> Comprehensive comparison validates LSTM superiority over CNN/RNN for sequence tasks</li>
        </ul>
      </section>

      <section>
        <h2>Tech Stack</h2>
        <div class="skill-tags">
          <span class="skill-tag">Python</span>
          <span class="skill-tag">TensorFlow</span>
          <span class="skill-tag">Keras</span>
          <span class="skill-tag">LSTM</span>
          <span class="skill-tag">CNN</span>
          <span class="skill-tag">RNN</span>
          <span class="skill-tag">NLTK</span>
          <span class="skill-tag">Numpy</span>
        </div>
      </section>

      <section>
        <h2>Key Learnings</h2>
        <ul style="list-style: disc; padding-left: 2rem;">
          <li>LSTMs excel at capturing long-term dependencies compared to vanilla RNNs</li>
          <li>Text preprocessing (tokenization, stopword removal) significantly impacts model performance</li>
          <li>Embedding layers reduce dimensionality and improve training efficiency</li>
          <li>Bidirectional LSTMs capture context from both directions for better sequence understanding</li>
          <li>Dropout and regularization are essential to prevent overfitting in deep learning</li>
        </ul>
      </section>

      <div style="margin-top: 3rem; padding-top: 2rem; border-top: 1px solid var(--color-light-border);">
        <div style="display: flex; gap: 2rem; justify-content: space-between; align-items: center;">
          <a href="/projects/customer-churn-prediction.html" class="btn btn-secondary">‚Üê Previous Project</a>
          <div style="display: flex; gap: 1rem;">
            <a href="/projects/coop-program-evaluation.html" class="btn">Next Project ‚Üí</a>
          </div>
        </div>
      </div>
    </article>
  </main>

  <footer>
    <p>&copy; 2024 Arjun Malgwa. All rights reserved.</p>
  </footer>

  <script defer src="/assets/js/motion.js"></script>
  <script defer src="/assets/js/main.js"></script>
</body>
</html>
